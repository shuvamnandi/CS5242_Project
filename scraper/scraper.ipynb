{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"scraper.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP0CQmxZjY2ZIwEPS2Q/hXl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"W786TemSA5xQ"},"source":["import re\n","import requests\n","from bs4 import BeautifulSoup\n","from urllib.parse import urlparse\n","import os\n","f = open(\"images_flowers.txt\", \"w\")\n","res=[]\n","def download_google(url):\n","    #url = 'https://www.google.com/search?q=flowers&sxsrf=ALeKk00uvzQYZFJo03cukIcMS-pcmmbuRQ:1589501547816&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjEm4LZyrTpAhWjhHIEHewPD1MQ_AUoAXoECBAQAw&biw=1440&bih=740'\n","    page = requests.get(url).text\n","    soup = BeautifulSoup(page, 'html.parser')\n","\n","    for raw_img in soup.find_all('img'):\n","        link = raw_img.get('src')\n","        res.append(link)\n","        if link:\n","            f.write(link +\"\\n\")\n","\n","\n","download_google('https://www.google.com/search?q=flowers&sxsrf=ALeKk00uvzQYZFJo03cukIcMS-pcmmbuRQ:1589501547816&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjEm4LZyrTpAhWjhHIEHewPD1MQ_AUoAXoECBAQAw&biw=1440&bih=740')\n","\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RdgmXI4GGDU","executionInfo":{"status":"ok","timestamp":1636200712246,"user_tz":-480,"elapsed":4732,"user":{"displayName":"Jun Hao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08829472405105851834"}},"outputId":"58492ec5-f850-4363-b35f-8e6d0413f7d9"},"source":["# importing google_images_download module \n","!pip install google_images_download\n","from google_images_download import google_images_download  \n","  \n","# creating object \n","response = google_images_download.googleimagesdownload()  \n","  \n","search_queries = ['flowers','birds'] \n","  \n","  \n","def downloadimages(query,n): \n","    # keywords is the search query \n","    # format is the image file format \n","    # limit is the number of images to be downloaded \n","    # print urs is to print the image file url \n","    # size is the image size which can \n","    # be specified manually (\"large, medium, icon\") \n","    # aspect ratio denotes the height width ratio \n","    # of images to download. (\"tall, square, wide, panoramic\") \n","    arguments = {\"keywords\": query, \n","                 \"format\": \"jpg\", \n","                 \"limit\":n, \n","                 \"print_urls\":True, \n","                 \"size\": \"medium\", \n","                 \"aspect_ratio\":\"panoramic\"} \n","    try: \n","        response.download(arguments) \n","      \n","    # Handling File NotFound Error     \n","    except FileNotFoundError:  \n","        arguments = {\"keywords\": query, \n","                     \"format\": \"jpg\", \n","                     \"limit\":n, \n","                     \"print_urls\":True,  \n","                     \"size\": \"medium\"} \n","                       \n","        # Providing arguments for the searched query \n","        try: \n","            # Downloading the photos based \n","            # on the given arguments \n","            response.download(arguments)  \n","        except: \n","            pass\n","  \n","# Driver Code \n","for query in search_queries: \n","    downloadimages(query,100)  \n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google_images_download in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (from google_images_download) (4.0.0)\n","Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium->google_images_download) (0.9.2)\n","Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium->google_images_download) (0.19.0)\n","Requirement already satisfied: urllib3[secure]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium->google_images_download) (1.26.7)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->google_images_download) (2.4.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->google_images_download) (1.2.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->google_images_download) (21.2.0)\n","Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->google_images_download) (1.1.0)\n","Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->google_images_download) (1.10)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium->google_images_download) (2.10)\n","Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium->google_images_download) (1.0.0)\n","Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium->google_images_download) (35.0.0)\n","Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium->google_images_download) (21.0.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium->google_images_download) (2021.5.30)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium->google_images_download) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium->google_images_download) (2.20)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium->google_images_download) (1.15.0)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google_images_download) (0.12.0)\n","\n","Item no.: 1 --> Item name = flowers\n","Evaluating...\n","Starting Download...\n","\n","\n","Unfortunately all 100 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n","\n","Errors: 0\n","\n","\n","\n","Item no.: 1 --> Item name = birds\n","Evaluating...\n","Starting Download...\n","\n","\n","Unfortunately all 100 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n","\n","Errors: 0\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"id":"TYC33P_QMtyS","executionInfo":{"status":"error","timestamp":1636201736113,"user_tz":-480,"elapsed":4712,"user":{"displayName":"Jun Hao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08829472405105851834"}},"outputId":"0138fedb-ec96-47c9-e1fe-3f1a0a2a0d7b"},"source":["\n","import time\n","from selenium import webdriver\n","# Chrome users change the below line to \n","from selenium.webdriver.chrome.options import Options\n","# from selenium.webdriver.firefox.options import Options\n","from selenium.webdriver.support.ui import WebDriverWait\n","from selenium.webdriver.support import expected_conditions as EC\n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.common.keys import Keys\n","import requests\n","import os\n","\n","URL = \"https://unsplash.com/\"\n","\n","image_name = input('Enter the image subject you want to download: ')\n","image_count= int(input('Number of images you want to download: '))\n","\n","options = Options()\n","options.headless = True\n","\n","print('Openning Firefox...', end='\\n\\n')\n","\n","# Chrome users change the below line to\n","browser = webdriver.Chrome(options = options)\n","# browser = webdriver.Firefox(options = options)\n","\n","wait = WebDriverWait(browser, 20)\n","\n","print('Going to %s' % URL, end='\\n\\n')\n","\n","print('Please wait...', end=\"\\n\\n\")\n","\n","browser.get(URL)\n","\n","try:\n","    search_bar = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div/div/header/nav/div[1]/div/form/div[1]/input')))\n","    search_bar.clear()\n","    search_bar.click()\n","    search_bar.send_keys(image_name, Keys.RETURN)\n","\n","except:\n","    print('Internet connection is too slow')\n","    browser.quit()\n","    exit()\n","\n","time.sleep(2)\n","\n","print('Searching images on %s...' % image_name, end=\"\\n\\n\")\n","\n","result_page = browser.find_element_by_tag_name(\"body\")\n","\n","no_of_pagedowns = 50\n","\n","print('Please wait...', end=\"\\n\\n\")\n","\n","while no_of_pagedowns:\n","    result_page.send_keys(Keys.ARROW_DOWN)\n","    time.sleep(0.4)\n","    no_of_pagedowns-=1\n","    \n","image_elements = browser.find_elements_by_class_name('_2UpQX')\n","\n","i = 0\n","files_count = 0\n","\n","if not os.path.exists('images'):\n","    os.mkdir('images')\n","    i = 1\n","else:\n","    files_count = len(os.listdir('images'))\n","    \n","i = files_count + 1\n","\n","for image_element in image_elements:\n","\n","    if i <= image_count + files_count:\n","\n","        image_name = image_element.get_attribute('alt')\n","\n","        if image_name == '':\n","            image_name = 'demo name'\n","\n","        image_link = image_element.get_attribute('src')\n","\n","        print('Downloading image %s...'% image_name)\n","\n","        image_data = requests.get(image_link)\n","\n","        try:\n","            image_data.raise_for_status()\n","        except Exception as e:\n","            print('There is a problem with this image: ' + e)\n","\n","        image_file = open('images/'+str(i)+'-'+image_name+'.jpg', 'wb')\n","\n","        for chunk in image_data.iter_content(100000):\n","            image_file.write(chunk)\n","\n","        image_file.close()\n","        print('Download status: Ok!', end='\\n\\n')\n","        i += 1\n","\n","    else:\n","\n","        break\n","\n","browser.quit()\n","\n","print('Images successfully downloaded! Please check ./images folder!')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the image subject you want to download: fish\n","Number of images you want to download: 10\n","Openning Firefox...\n","\n"]},{"output_type":"error","ename":"WebDriverException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                             \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                                             creationflags=self.creationflags)\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chromedriver': 'chromedriver'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-36aab40edc7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Chrome users change the below line to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mbrowser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# browser = webdriver.Firefox(options = options)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     70\u001b[0m                                         \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                                         \u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_capabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                                         service_log_path, service, keep_alive)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     85\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 86\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     87\u001b[0m                 )\n\u001b[1;32m     88\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"]}]},{"cell_type":"code","metadata":{"id":"ySEvTeVBGGdm"},"source":["/** js code\n"," * simulate a right-click event so we can grab the image URL using the\n"," * context menu alleviating the need to navigate to another page\n"," *\n"," * attributed to @jmiserez: http://pyimg.co/9qe7y\n"," *\n"," * @param   {object}  element  DOM Element\n"," *\n"," * @return  {void}\n"," */\n","function simulateRightClick( element ) {\n","    var event1 = new MouseEvent( 'mousedown', {\n","        bubbles: true,\n","        cancelable: false,\n","        view: window,\n","        button: 2,\n","        buttons: 2,\n","        clientX: element.getBoundingClientRect().x,\n","        clientY: element.getBoundingClientRect().y\n","    } );\n","    element.dispatchEvent( event1 );\n","    var event2 = new MouseEvent( 'mouseup', {\n","        bubbles: true,\n","        cancelable: false,\n","        view: window,\n","        button: 2,\n","        buttons: 0,\n","        clientX: element.getBoundingClientRect().x,\n","        clientY: element.getBoundingClientRect().y\n","    } );\n","    element.dispatchEvent( event2 );\n","    var event3 = new MouseEvent( 'contextmenu', {\n","        bubbles: true,\n","        cancelable: false,\n","        view: window,\n","        button: 2,\n","        buttons: 0,\n","        clientX: element.getBoundingClientRect().x,\n","        clientY: element.getBoundingClientRect().y\n","    } );\n","    element.dispatchEvent( event3 );\n","}\n","\n","/**\n"," * grabs a URL Parameter from a query string because Google Images\n"," * stores the full image URL in a query parameter\n"," *\n"," * @param   {string}  queryString  The Query String\n"," * @param   {string}  key          The key to grab a value for\n"," *\n"," * @return  {string}               value\n"," */\n","function getURLParam( queryString, key ) {\n","    var vars = queryString.replace( /^\\?/, '' ).split( '&' );\n","    for ( let i = 0; i < vars.length; i++ ) {\n","        let pair = vars[ i ].split( '=' );\n","        if ( pair[0] == key ) {\n","            return pair[1];\n","        }\n","    }\n","    return false;\n","}\n","\n","/**\n"," * Generate and automatically download a txt file from the URL contents\n"," *\n"," * @param   {string}  contents  The contents to download\n"," *\n"," * @return  {void}\n"," */\n","function createDownload( contents ) {\n","    var hiddenElement = document.createElement( 'a' );\n","    hiddenElement.href = 'data:attachment/text,' + encodeURI( contents );\n","    hiddenElement.target = '_blank';\n","    hiddenElement.download = 'urls.txt';\n","    hiddenElement.click();\n","}\n","\n","/**\n"," * grab all URLs va a Promise that resolves once all URLs have been\n"," * acquired\n"," *\n"," * @return  {object}  Promise object\n"," */\n","function grabUrls() {\n","    var urls = [];\n","    return new Promise( function( resolve, reject ) {\n","        var count = document.querySelectorAll(\n","        \t'.isv-r a:first-of-type' ).length,\n","            index = 0;\n","        Array.prototype.forEach.call( document.querySelectorAll(\n","        \t'.isv-r a:first-of-type' ), function( element ) {\n","            // using the right click menu Google will generate the\n","            // full-size URL; won't work in Internet Explorer\n","            // (http://pyimg.co/byukr)\n","            simulateRightClick( element.querySelector( ':scope img' ) );\n","            // Wait for it to appear on the <a> element\n","            var interval = setInterval( function() {\n","                if ( element.href.trim() !== '' ) {\n","                    clearInterval( interval );\n","                    // extract the full-size version of the image\n","                    let googleUrl = element.href.replace( /.*(\\?)/, '$1' ),\n","                        fullImageUrl = decodeURIComponent(\n","                        \tgetURLParam( googleUrl, 'imgurl' ) );\n","                    if ( fullImageUrl !== 'false' ) {\n","                        urls.push( fullImageUrl );\n","                    }\n","                    // sometimes the URL returns a \"false\" string and\n","                    // we still want to count those so our Promise\n","                    // resolves\n","                    index++;\n","                    if ( index == ( count - 1 ) ) {\n","                        resolve( urls );\n","                    }\n","                }\n","            }, 10 );\n","        } );\n","    } );\n","}\n","\n","/**\n"," * Call the main function to grab the URLs and initiate the download\n"," */\n","grabUrls().then( function( urls ) {\n","    urls = urls.join( '\\n' );\n","    createDownload( urls );\n","} );"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"scF3oZ01GGg2"},"source":["# USAGE\n","# python download_images.py --urls urls.txt --output images/santa\n","\n","# import the necessary packages\n","from imutils import paths\n","import argparse\n","import requests\n","import cv2\n","import os\n","\n","# construct the argument parse and parse the arguments\n","ap = argparse.ArgumentParser()\n","ap.add_argument(\"-u\", \"--urls\", required=True,\n","\thelp=\"path to file containing image URLs\")\n","ap.add_argument(\"-o\", \"--output\", required=True,\n","\thelp=\"path to output directory of images\")\n","args = vars(ap.parse_args())\n","\n","# grab the list of URLs from the input file, then initialize the\n","# total number of images downloaded thus far\n","rows = open(args[\"urls\"]).read().strip().split(\"\\n\")\n","total = 0\n","\n","# loop the URLs\n","for url in rows:\n","\ttry:\n","\t\t# try to download the image\n","\t\tr = requests.get(url, timeout=60)\n","\n","\t\t# save the image to disk\n","\t\tp = os.path.sep.join([args[\"output\"], \"{}.jpg\".format(\n","\t\t\tstr(total).zfill(8))])\n","\t\tf = open(p, \"wb\")\n","\t\tf.write(r.content)\n","\t\tf.close()\n","\n","\t\t# update the counter\n","\t\tprint(\"[INFO] downloaded: {}\".format(p))\n","\t\ttotal += 1\n","\n","\t# handle if any exceptions are thrown during the download process\n","\texcept:\n","\t\tprint(\"[INFO] error downloading {}...skipping\".format(p))\n","\n","# loop over the image paths we just downloaded\n","for imagePath in paths.list_images(args[\"output\"]):\n","\t# initialize if the image should be deleted or not\n","\tdelete = False\n","\n","\t# try to load the image\n","\ttry:\n","\t\timage = cv2.imread(imagePath)\n","\n","\t\t# if the image is `None` then we could not properly load it\n","\t\t# from disk, so delete it\n","\t\tif image is None:\n","\t\t\tprint(\"None\")\n","\t\t\tdelete = True\n","\n","\t# if OpenCV cannot load the image then the image is likely\n","\t# corrupt so we should delete it\n","\texcept:\n","\t\tprint(\"Except\")\n","\t\tdelete = True\n","\n","\t# check to see if the image should be deleted\n","\tif delete:\n","\t\tprint(\"[INFO] deleting {}\".format(imagePath))\n","\t\tos.remove(imagePath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"mLqNuN2rE26k","executionInfo":{"status":"error","timestamp":1636209285783,"user_tz":-480,"elapsed":4123,"user":{"displayName":"Jun Hao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08829472405105851834"}},"outputId":"0ca0bcef-6f5d-445c-e23b-78548c4e0d17"},"source":["!pip install scrapy\n","# !pip install selenium\n","import time\n","import scrapy\n","from scrapy.crawler import CrawlerProcess\n","\n","\n","class MaskItem(scrapy.Item):\n","    file_urls = scrapy.Field()\n","\n","class MaskSpider(scrapy.Spider):\n","    name = \"mask\"\n","\n","    start_urls = [\n","        \"https://www.google.com/\"\n","    ]\n","  #   headers = {\n","  #     'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:48.0) Gecko/20100101 Firefox/48.0'\n","  #  }\n","\n","    def parse(self, response):\n","        for mask_item in response.css(\".photo-item\"):\n","            url = mask_item.css('img::attr(\"src\")').extract_first().split(\"?\")[0]\n","            yield MaskItem(file_urls=[url])\n","\n","        next_page = response.css('.next_page::attr(\"href\")').extract_first()\n","        if next_page is not None:\n","            yield response.follow(next_page, self.parse)\n","\n","process = CrawlerProcess()\n","process.crawl(MaskSpider)\n","# time.sleep(0.5)\n","process.start()\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scrapy in /usr/local/lib/python3.7/dist-packages (2.5.1)\n","Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.0.4)\n","Requirement already satisfied: service-identity>=16.0.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.1.0)\n","Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.2.6)\n","Requirement already satisfied: pyOpenSSL>=16.2.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.0.0)\n","Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.4.0)\n","Requirement already satisfied: h2<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (3.2.0)\n","Requirement already satisfied: Twisted[http2]>=17.9.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.7.0)\n","Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.1.16)\n","Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.0.5)\n","Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.1.0)\n","Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.0)\n","Requirement already satisfied: zope.interface>=4.1.3 in /usr/local/lib/python3.7/dist-packages (from scrapy) (5.4.0)\n","Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.2)\n","Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.22.0)\n","Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (35.0.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->scrapy) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->scrapy) (2.20)\n","Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2<4.0,>=3.0->scrapy) (3.0.0)\n","Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2<4.0,>=3.0->scrapy) (5.2.0)\n","Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.7/dist-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\n","Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (21.2.0)\n","Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n","Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n","Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted[http2]>=17.9.0->scrapy) (21.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted[http2]>=17.9.0->scrapy) (3.7.4.3)\n","Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted[http2]>=17.9.0->scrapy) (20.2.0)\n","Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted[http2]>=17.9.0->scrapy) (21.0.0)\n","Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted[http2]>=17.9.0->scrapy) (15.1.0)\n","Requirement already satisfied: priority<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from Twisted[http2]>=17.9.0->scrapy) (1.3.0)\n","Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted[http2]>=17.9.0->scrapy) (2.10)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface>=4.1.3->scrapy) (57.4.0)\n"]},{"output_type":"stream","name":"stderr","text":["2021-11-06 14:34:44 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: scrapybot)\n","2021-11-06 14:34:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.7.12 (default, Sep 10 2021, 00:21:48) - [GCC 7.5.0], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic\n","2021-11-06 14:34:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n","2021-11-06 14:34:44 [scrapy.crawler] INFO: Overridden settings:\n","{}\n","2021-11-06 14:34:44 [scrapy.extensions.telnet] INFO: Telnet Password: 3e354a576eef746e\n","2021-11-06 14:34:44 [scrapy.middleware] INFO: Enabled extensions:\n","['scrapy.extensions.corestats.CoreStats',\n"," 'scrapy.extensions.telnet.TelnetConsole',\n"," 'scrapy.extensions.memusage.MemoryUsage',\n"," 'scrapy.extensions.logstats.LogStats']\n","2021-11-06 14:34:44 [scrapy.middleware] INFO: Enabled downloader middlewares:\n","['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n"," 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n"," 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n"," 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n"," 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n"," 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n"," 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n"," 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n"," 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n"," 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n","2021-11-06 14:34:44 [scrapy.middleware] INFO: Enabled spider middlewares:\n","['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n"," 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n"," 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n"," 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n"," 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n","2021-11-06 14:34:44 [scrapy.middleware] INFO: Enabled item pipelines:\n","[]\n","2021-11-06 14:34:44 [scrapy.core.engine] INFO: Spider opened\n","2021-11-06 14:34:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n","2021-11-06 14:34:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6029\n"]},{"output_type":"error","ename":"ReactorNotRestartable","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mReactorNotRestartable\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-533766efbc02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaskSpider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# time.sleep(0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, stop_after_crawl)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjustPoolsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'REACTOR_THREADPOOL_MAXSIZE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddSystemEventTrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shutdown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_graceful_stop_reactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \"\"\"\n\u001b[1;32m   1298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_installSignalHandlers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m         \u001b[0mReactorBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReactorBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reallyStartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorAlreadyRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_startedBefore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorNotRestartable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mReactorNotRestartable\u001b[0m: "]}]}]}